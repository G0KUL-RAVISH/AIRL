{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b5514500",
      "metadata": {
        "id": "b5514500"
      },
      "source": [
        "# Q1 — Vision Transformer (ViT) on CIFAR-10 (Patched v3)\n",
        "\n",
        "Speed patches + explicit ViT class + results table & JSON at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "24784d0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24784d0c",
        "outputId": "561e9828-d464-432f-db24-1ca8712791bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/983.2 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.8.0+cu126\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "VRAM (GB): 15.83\n"
          ]
        }
      ],
      "source": [
        "!pip -q install torch torchvision torchmetrics tqdm --upgrade\n",
        "\n",
        "import os, sys, json, math, time, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"VRAM (GB):\", round(torch.cuda.get_device_properties(0).total_memory/1e9, 2))\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"medium\")\n",
        "except Exception as e:\n",
        "    print(\"TF32 setting skipped:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21184641",
      "metadata": {
        "id": "21184641"
      },
      "source": [
        "## Config (single source of truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d4d52521",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4d52521",
        "outputId": "c296981e-614e-424c-af19-53584078bea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"run_id\": \"vit_cifar10_v3_20251004-101042\",\n",
            "  \"seed\": 42,\n",
            "  \"device\": \"cuda\",\n",
            "  \"input_size\": 32,\n",
            "  \"patch_size\": 4,\n",
            "  \"num_classes\": 10,\n",
            "  \"val_split\": 5000,\n",
            "  \"randaugment\": {\n",
            "    \"enabled\": true,\n",
            "    \"N\": 2,\n",
            "    \"M\": 10\n",
            "  },\n",
            "  \"mixup\": {\n",
            "    \"p\": 0.5,\n",
            "    \"alpha\": 0.2\n",
            "  },\n",
            "  \"cutmix\": {\n",
            "    \"p\": 0.0,\n",
            "    \"alpha\": 1.0\n",
            "  },\n",
            "  \"label_smoothing\": 0.1,\n",
            "  \"embed_dim\": 384,\n",
            "  \"depth\": 12,\n",
            "  \"num_heads\": 6,\n",
            "  \"mlp_ratio\": 4.0,\n",
            "  \"drop_path\": 0.1,\n",
            "  \"dropout\": 0.0,\n",
            "  \"epochs\": 100,\n",
            "  \"batch_size_target\": 512,\n",
            "  \"grad_accum_steps\": 1,\n",
            "  \"optimizer\": {\n",
            "    \"name\": \"AdamW\",\n",
            "    \"lr\": 0.0006,\n",
            "    \"weight_decay\": 0.1,\n",
            "    \"betas\": [\n",
            "      0.9,\n",
            "      0.999\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"scheduler\": {\n",
            "    \"type\": \"cosine\",\n",
            "    \"warmup_epochs\": 10\n",
            "  },\n",
            "  \"ema_decay\": 0.2,\n",
            "  \"grad_clip\": 1.0,\n",
            "  \"use_amp\": true,\n",
            "  \"out_dir\": \"./outputs\",\n",
            "  \"eval_every\": 5\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#CONFIG\n",
        "def now_str():\n",
        "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "config = {\n",
        "    \"run_id\": f\"vit_cifar10_v3_{now_str()}\",\n",
        "    \"seed\": 42,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"input_size\": 32,\n",
        "    \"patch_size\": 4,\n",
        "    \"num_classes\": 10,\n",
        "    \"val_split\": 5000,\n",
        "    \"randaugment\": {\"enabled\": True, \"N\": 2, \"M\": 10},\n",
        "    \"mixup\": {\"p\": 0.5, \"alpha\": 0.2},\n",
        "    \"cutmix\": {\"p\": 0.0, \"alpha\": 1.0},\n",
        "    \"label_smoothing\": 0.1,\n",
        "    \"embed_dim\": 384,\n",
        "    \"depth\": 12,\n",
        "    \"num_heads\": 6,\n",
        "    \"mlp_ratio\": 4.0,\n",
        "    \"drop_path\": 0.1,\n",
        "    \"dropout\": 0.0,\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size_target\": 512,\n",
        "    \"grad_accum_steps\": 1,\n",
        "    \"optimizer\": {\"name\":\"AdamW\",\"lr\":6e-4,\"weight_decay\":0.1,\"betas\":(0.9,0.999),\"eps\":1e-8},\n",
        "    \"scheduler\": {\"type\":\"cosine\",\"warmup_epochs\":10},\n",
        "    \"ema_decay\": 0.2,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"use_amp\": True,\n",
        "    \"out_dir\": \"./outputs\",\n",
        "    \"eval_every\": 5\n",
        "}\n",
        "CFG = config\n",
        "os.makedirs(CFG[\"out_dir\"], exist_ok=True)\n",
        "print(json.dumps(CFG, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bf923f2",
      "metadata": {
        "id": "1bf923f2"
      },
      "source": [
        "## Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "022d8ee8",
      "metadata": {
        "id": "022d8ee8"
      },
      "outputs": [],
      "source": [
        "#@title Seeds & cuDNN\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "set_seed(CFG[\"seed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ee651e1",
      "metadata": {
        "id": "6ee651e1"
      },
      "source": [
        "## Data & Augmentations (fast DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0fc8ccfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fc8ccfa",
        "outputId": "2640db66-1d33-4e43-c30f-ba7254cd20f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 45000 | Val size: 5000 | Test size: 10000\n"
          ]
        }
      ],
      "source": [
        "#Data pipeline\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "def build_transforms(input_size: int, ra_cfg: dict):\n",
        "    if input_size == 32:\n",
        "        train_tfms = [\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ]\n",
        "    else:\n",
        "        train_tfms = [\n",
        "            transforms.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
        "            transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), interpolation=InterpolationMode.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ]\n",
        "    if ra_cfg.get(\"enabled\", False):\n",
        "        N, M = ra_cfg.get(\"N\", 2), ra_cfg.get(\"M\", 10)\n",
        "        train_tfms.append(transforms.RandAugment(num_ops=N, magnitude=M))\n",
        "    train_tfms += [transforms.ToTensor(), transforms.Normalize(CIFAR_MEAN, CIFAR_STD)]\n",
        "    test_tfms = [\n",
        "        transforms.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
        "    ]\n",
        "    return transforms.Compose(train_tfms), transforms.Compose(test_tfms)\n",
        "\n",
        "train_tfms, test_tfms = build_transforms(CFG[\"input_size\"], CFG[\"randaugment\"])\n",
        "data_root = \"./data\"\n",
        "full_train = datasets.CIFAR10(root=data_root, train=True, download=True, transform=train_tfms)\n",
        "test_set   = datasets.CIFAR10(root=data_root, train=False, download=True, transform=test_tfms)\n",
        "\n",
        "val_size = CFG[\"val_split\"]\n",
        "train_size = len(full_train) - val_size\n",
        "train_set, val_set = random_split(full_train, [train_size, val_size], generator=torch.Generator().manual_seed(CFG[\"seed\"]))\n",
        "\n",
        "def make_loader(ds, batch_size, shuffle=False):\n",
        "    import os\n",
        "    num_workers = max(2, min(8, os.cpu_count() - 1 if os.cpu_count() else 2))\n",
        "    return DataLoader(\n",
        "        ds, batch_size=batch_size, shuffle=shuffle,\n",
        "        num_workers=num_workers, pin_memory=True,\n",
        "        prefetch_factor=2, persistent_workers=True,\n",
        "    )\n",
        "\n",
        "print(f\"Train size: {len(train_set)} | Val size: {len(val_set)} | Test size: {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8804398b",
      "metadata": {
        "id": "8804398b"
      },
      "source": [
        "## MixUp & CutMix helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "06420936",
      "metadata": {
        "id": "06420936"
      },
      "outputs": [],
      "source": [
        "#@title MixUp & CutMix\n",
        "import numpy as np, random\n",
        "\n",
        "def rand_bbox(W, H, lam):\n",
        "    cut_rat = (1. - lam) ** 0.5\n",
        "    cut_w = int(W * cut_rat); cut_h = int(H * cut_rat)\n",
        "    cx = np.random.randint(W); cy = np.random.randint(H)\n",
        "    x1 = np.clip(cx - cut_w // 2, 0, W); y1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    x2 = np.clip(cx + cut_w // 2, 0, W); y2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def apply_mixup_cutmix(x, y, num_classes, mixup_cfg, cutmix_cfg):\n",
        "    B, C, H, W = x.shape\n",
        "    y_onehot = torch.zeros(B, num_classes, device=x.device, dtype=x.dtype)\n",
        "    y_onehot.scatter_(1, y.view(-1,1), 1.0)\n",
        "\n",
        "    r = random.random()\n",
        "    if r < mixup_cfg.get(\"p\", 0.0):\n",
        "        alpha = mixup_cfg.get(\"alpha\", 0.2)\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        index = torch.randperm(B, device=x.device)\n",
        "        x = lam * x + (1 - lam) * x[index, :]\n",
        "        y_soft = lam * y_onehot + (1 - lam) * y_onehot[index, :]\n",
        "        return x, y_soft, True\n",
        "\n",
        "    if r < (mixup_cfg.get(\"p\", 0.0) + cutmix_cfg.get(\"p\", 0.0)):\n",
        "        alpha = cutmix_cfg.get(\"alpha\", 1.0)\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        index = torch.randperm(B, device=x.device)\n",
        "        x1, y1, x2, y2 = rand_bbox(W, H, lam)\n",
        "        x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "        lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
        "        y_soft = lam * y_onehot + (1 - lam) * y_onehot[index, :]\n",
        "        return x, y_soft, True\n",
        "\n",
        "    return x, y_onehot, False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239aad2a",
      "metadata": {
        "id": "239aad2a"
      },
      "source": [
        "## ViT (SDPA/Flash) + explicit `ViT` wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e9bf06eb",
      "metadata": {
        "id": "e9bf06eb"
      },
      "outputs": [],
      "source": [
        "#ViT (with SDPA/Flash)\n",
        "class DropPath(nn.Module):\n",
        "    def __init__(self, drop_prob: float = 0.):\n",
        "        super().__init__(); self.drop_prob = drop_prob\n",
        "    def forward(self, x):\n",
        "        if self.drop_prob == 0. or not self.training: return x\n",
        "        keep = 1 - self.drop_prob\n",
        "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        rand = keep + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "        rand.floor_()\n",
        "        return x.div(keep) * rand\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, mlp_ratio=4.0, drop=0.0):\n",
        "        super().__init__()\n",
        "        hidden = int(dim * mlp_ratio)\n",
        "        self.fc1 = nn.Linear(dim, hidden); self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden, dim); self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x); x = self.act(x); x = self.drop(x)\n",
        "        x = self.fc2(x); x = self.drop(x); return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, attn_drop=0.0, proj_drop=0.0):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0\n",
        "        self.num_heads = num_heads; self.head_dim = dim // num_heads\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.attn_drop = nn.Dropout(attn_drop); self.proj_drop = nn.Dropout(proj_drop)\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2,0,3,1,4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=True, enable_mem_efficient=True):\n",
        "            out = F.scaled_dot_product_attention(q, k, v, dropout_p=0.0, is_causal=False)\n",
        "        x = out.transpose(1,2).reshape(B, N, C)\n",
        "        x = self.proj(x); x = self.proj_drop(x); return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.0, drop_path=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim); self.attn = Attention(dim, num_heads=num_heads)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = nn.LayerNorm(dim); self.mlp = MLP(dim, mlp_ratio=mlp_ratio, drop=drop)\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x))); return x\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=192):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0\n",
        "        self.grid = img_size // patch_size; self.num_patches = self.grid * self.grid\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x); x = x.flatten(2).transpose(1, 2); return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=10,\n",
        "                 embed_dim=192, depth=8, num_heads=3, mlp_ratio=4.0,\n",
        "                 drop_rate=0.0, drop_path=0.0):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + num_patches, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path, depth)]\n",
        "        self.blocks = nn.ModuleList([Block(embed_dim, num_heads, mlp_ratio, drop_rate, dpr[i]) for i in range(depth)])\n",
        "        self.norm = nn.LayerNorm(embed_dim); self.head = nn.Linear(embed_dim, num_classes)\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02); nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(self._init_weights)\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02);\n",
        "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n",
        "    def forward_features(self, x):\n",
        "        x = self.patch_embed(x); B, N, C = x.shape\n",
        "        x = torch.cat([self.cls_token.expand(B, -1, -1), x], dim=1) + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "        for blk in self.blocks: x = blk(x)\n",
        "        x = self.norm(x); return x[:, 0]\n",
        "    def forward(self, x): return self.head(self.forward_features(x))\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, num_classes, embed_dim, depth, num_heads,\n",
        "                 mlp_ratio=4.0, drop_rate=0.0, drop_path=0.0):\n",
        "        super().__init__()\n",
        "        self.core = VisionTransformer(img_size, patch_size, 3, num_classes, embed_dim, depth, num_heads, mlp_ratio, drop_rate, drop_path)\n",
        "    def forward(self, x): return self.core(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a8c725",
      "metadata": {
        "id": "55a8c725"
      },
      "source": [
        "## Optimizer / Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b891b41f",
      "metadata": {
        "id": "b891b41f"
      },
      "outputs": [],
      "source": [
        "# Optimizer / Scheduler\n",
        "def split_weight_decay_params(model: nn.Module):\n",
        "    decay, no_decay = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if p.ndimension() == 1 or name.endswith(\".bias\") or \"norm\" in name.lower():\n",
        "            no_decay.append(p)\n",
        "        else:\n",
        "            decay.append(p)\n",
        "    return [\n",
        "        {\"params\": decay, \"weight_decay\": CFG[\"optimizer\"][\"weight_decay\"]},\n",
        "        {\"params\": no_decay, \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "def build_optimizer(model):\n",
        "    groups = split_weight_decay_params(model)\n",
        "    return torch.optim.AdamW(groups, lr=CFG[\"optimizer\"][\"lr\"], betas=CFG[\"optimizer\"][\"betas\"], eps=CFG[\"optimizer\"][\"eps\"])\n",
        "\n",
        "def build_scheduler(optimizer, steps_per_epoch):\n",
        "    total_epochs = CFG[\"epochs\"]\n",
        "    warmup_epochs = CFG[\"scheduler\"][\"warmup_epochs\"]\n",
        "    warmup_steps = warmup_epochs * steps_per_epoch\n",
        "    total_steps  = total_epochs * steps_per_epoch\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps: return float(step) / float(max(1, warmup_steps))\n",
        "        progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff6b911",
      "metadata": {
        "id": "7ff6b911"
      },
      "source": [
        "## Train / Eval (eval-every-N, optional EMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a7f107d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f107d0",
        "outputId": "48bb4a40-ea3e-45e4-d8c4-124f0be156ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1598513610.py:59: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=CFG[\"use_amp\"] and device.type==\"cuda\")\n",
            "Epoch 1/100 (bs=512, eff=512):   0%|          | 0/88 [00:00<?, ?it/s]/tmp/ipython-input-1598513610.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"] and device.type==\"cuda\"):\n",
            "/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] val_acc=45.73% | test_acc=51.35% | lr=6.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] val_acc=47.60% | test_acc=54.42% | lr=1.20e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15] val_acc=45.51% | test_acc=51.10% | lr=1.19e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] val_acc=47.18% | test_acc=54.39% | lr=1.16e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 25] val_acc=46.41% | test_acc=53.80% | lr=1.12e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30] val_acc=50.52% | test_acc=57.21% | lr=1.06e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 35] val_acc=51.39% | test_acc=56.48% | lr=9.86e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 40] val_acc=51.44% | test_acc=55.13% | lr=9.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 45] val_acc=51.89% | test_acc=59.46% | lr=8.05e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 50] val_acc=53.81% | test_acc=60.67% | lr=7.04e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 55] val_acc=54.83% | test_acc=61.08% | lr=6.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 60] val_acc=57.72% | test_acc=63.68% | lr=4.96e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 65] val_acc=59.55% | test_acc=64.97% | lr=3.95e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 70] val_acc=61.26% | test_acc=66.61% | lr=3.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 75] val_acc=62.87% | test_acc=69.22% | lr=2.14e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 80] val_acc=64.48% | test_acc=70.15% | lr=1.40e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 85] val_acc=65.49% | test_acc=71.01% | lr=8.04e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 90] val_acc=65.30% | test_acc=72.01% | lr=3.62e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 95] val_acc=66.15% | test_acc=71.93% | lr=9.12e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 100] val_acc=66.04% | test_acc=71.96% | lr=0.00e+00\n"
          ]
        }
      ],
      "source": [
        "# Train / Eval\n",
        "def try_loader_oom(ds, target_bs, shuffle):\n",
        "    bs = target_bs\n",
        "    while bs >= 8:\n",
        "        try:\n",
        "            loader = make_loader(ds, bs, shuffle=shuffle)\n",
        "            xb, yb = next(iter(loader))\n",
        "            xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
        "            del xb, yb\n",
        "            return loader, bs\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "                bs //= 2\n",
        "            else:\n",
        "                raise e\n",
        "    return make_loader(ds, 8, shuffle=shuffle), 8\n",
        "\n",
        "def build_model_and_optimizer():\n",
        "    model = ViT(\n",
        "        img_size=CFG[\"input_size\"], patch_size=CFG[\"patch_size\"], num_classes=CFG[\"num_classes\"],\n",
        "        embed_dim=CFG[\"embed_dim\"], depth=CFG[\"depth\"], num_heads=CFG[\"num_heads\"],\n",
        "        mlp_ratio=CFG[\"mlp_ratio\"], drop_rate=CFG[\"dropout\"], drop_path=CFG[\"drop_path\"],\n",
        "    ).to(device)\n",
        "    opt = build_optimizer(model)\n",
        "    return model, opt\n",
        "\n",
        "def smoothed_cross_entropy(logits, targets, smoothing, num_classes):\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    with torch.no_grad():\n",
        "        true_dist = torch.zeros_like(log_probs)\n",
        "        true_dist.fill_(smoothing / (num_classes - 1))\n",
        "        true_dist.scatter_(1, targets.data.unsqueeze(1), 1.0 - smoothing)\n",
        "    return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    acc = MulticlassAccuracy(num_classes=CFG[\"num_classes\"]).to(device)\n",
        "    total_loss, n = 0.0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        acc.update(logits, y)\n",
        "        total_loss += loss.item() * x.size(0); n += x.size(0)\n",
        "    return total_loss / n, acc.compute().item()\n",
        "\n",
        "def train():\n",
        "    model, opt = build_model_and_optimizer()\n",
        "    train_loader, train_bs = try_loader_oom(train_set, CFG[\"batch_size_target\"], shuffle=True)\n",
        "    val_loader, _ = try_loader_oom(val_set, min(train_bs, CFG[\"batch_size_target\"]), shuffle=False)\n",
        "    test_loader,_ = try_loader_oom(test_set, min(train_bs, CFG[\"batch_size_target\"]), shuffle=False)\n",
        "\n",
        "    effective_bs = train_bs * CFG[\"grad_accum_steps\"]\n",
        "    scaled_lr = CFG[\"optimizer\"][\"lr\"] * (effective_bs / 256.0)\n",
        "    for pg in opt.param_groups: pg[\"lr\"] = scaled_lr\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG[\"use_amp\"] and device.type==\"cuda\")\n",
        "    scheduler = build_scheduler(opt, steps_per_epoch=len(train_loader))\n",
        "\n",
        "    use_ema = CFG.get(\"ema_decay\", 0.0) and CFG[\"ema_decay\"] > 0.0\n",
        "    if use_ema:\n",
        "        import copy\n",
        "        ema = copy.deepcopy(model).to(device)\n",
        "        for p in ema.parameters(): p.requires_grad_(False)\n",
        "    else:\n",
        "        ema = None\n",
        "\n",
        "    best_val = 0.0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(CFG[\"epochs\"]):\n",
        "        model.train()\n",
        "        tbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CFG['epochs']} (bs={train_bs}, eff={effective_bs})\", leave=False)\n",
        "        running_loss, running_acc, seen = 0.0, 0.0, 0\n",
        "        acc = MulticlassAccuracy(num_classes=CFG[\"num_classes\"]).to(device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for step, (x, y) in enumerate(tbar):\n",
        "            x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
        "            x_in, soft_targets, used_soft = apply_mixup_cutmix(x, y, CFG[\"num_classes\"], CFG[\"mixup\"], CFG[\"cutmix\"])\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"] and device.type==\"cuda\"):\n",
        "                logits = model(x_in)\n",
        "                if used_soft:\n",
        "                    loss = torch.mean(torch.sum(-soft_targets * F.log_softmax(logits, dim=-1), dim=-1))\n",
        "                else:\n",
        "                    ls = CFG[\"label_smoothing\"]\n",
        "                    loss = smoothed_cross_entropy(logits, y, ls, CFG[\"num_classes\"]) if ls and ls>0 else F.cross_entropy(logits, y)\n",
        "\n",
        "            scaler.scale(loss / CFG[\"grad_accum_steps\"]).backward()\n",
        "\n",
        "            if (step + 1) % CFG[\"grad_accum_steps\"] == 0:\n",
        "                if CFG[\"grad_clip\"] and CFG[\"grad_clip\"] > 0:\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True); scheduler.step()\n",
        "\n",
        "                if use_ema:\n",
        "                    with torch.no_grad():\n",
        "                        d = CFG[\"ema_decay\"]\n",
        "                        for p_ema, p in zip(ema.parameters(), model.parameters()):\n",
        "                            p_ema.copy_(p_ema * d + p * (1.0 - d))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                acc.update(logits, y)\n",
        "                running_loss += loss.item() * x.size(0)\n",
        "                seen += x.size(0); running_acc = acc.compute().item()\n",
        "                tbar.set_postfix(loss=f\"{running_loss/seen:.4f}\", acc=f\"{running_acc*100:.2f}%\")\n",
        "\n",
        "        do_eval = ((epoch + 1) % CFG[\"eval_every\"] == 0) or ((epoch + 1) == CFG[\"epochs\"])\n",
        "        val_loss = val_acc = test_loss = test_acc = None\n",
        "        if do_eval:\n",
        "            m_eval = ema if use_ema else model\n",
        "            val_loss, val_acc = evaluate(m_eval, val_loader)\n",
        "            test_loss, test_acc = evaluate(m_eval, test_loader)\n",
        "            print(f\"[Epoch {epoch+1}] val_acc={val_acc*100:.2f}% | test_acc={test_acc*100:.2f}% | lr={scheduler.get_last_lr()[0]:.2e}\")\n",
        "            if val_acc > best_val:\n",
        "                best_val = val_acc\n",
        "                ckpt = {\"epoch\": epoch+1, \"model\": \"ViT\", \"state_dict\": m_eval.state_dict(), \"cfg\": CFG, \"best_val_acc\": best_val}\n",
        "                torch.save(ckpt, os.path.join(CFG[\"out_dir\"], f\"{CFG['run_id']}_best.pt\"))\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch+1, \"train_loss\": running_loss/seen, \"train_acc\": running_acc,\n",
        "            \"val_loss\": val_loss, \"val_acc\": val_acc, \"test_loss\": test_loss, \"test_acc\": test_acc,\n",
        "            \"lr\": scheduler.get_last_lr()[0], \"batch_size\": train_bs, \"effective_bs\": effective_bs,\n",
        "        })\n",
        "\n",
        "    results = {\"run_id\": CFG[\"run_id\"], \"config\": CFG, \"best_val_acc\": best_val,\n",
        "               \"last_epoch\": history[-1] if history else None,\n",
        "               \"history_tail\": history[-5:] if len(history) > 5 else history}\n",
        "    with open(os.path.join(CFG[\"out_dir\"], \"results.json\"), \"w\") as f: json.dump(results, f, indent=2)\n",
        "    with open(os.path.join(CFG[\"out_dir\"], \"best_config.json\"), \"w\") as f: json.dump(CFG, f, indent=2)\n",
        "    return results, history\n",
        "\n",
        "results, history = train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c559833",
      "metadata": {
        "id": "8c559833"
      },
      "source": [
        "## Final Test evaluation + tiny results table + final JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "77f39999",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77f39999",
        "outputId": "d73af9ff-afde-4537-f68f-04c38745c5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results row: {'input': 32, 'patch': 4, 'dim': 384, 'depth': 12, 'heads': 6, 'drop_path': 0.1, 'epochs': 100, 'test_acc%': 71.93}\n",
            "\n",
            "| Config | Input | Patch | Dim | Depth | Heads | DropPath | Epochs | Test Acc (%) |\n",
            "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
            "| vit_cifar10_v3_20251004-101042 | 32×32 | 4 | 384 | 12 | 6 | 0.1 | 100 | **71.93** |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Final evaluation & table\n",
        "best_ckpts = [f for f in os.listdir(CFG[\"out_dir\"]) if f.endswith(\"_best.pt\")]\n",
        "best_path = max([os.path.join(CFG[\"out_dir\"], f) for f in best_ckpts], key=os.path.getmtime) if best_ckpts else None\n",
        "\n",
        "if best_path:\n",
        "    ckpt = torch.load(best_path, map_location=device)\n",
        "    model_eval = ViT(\n",
        "        img_size=CFG[\"input_size\"], patch_size=CFG[\"patch_size\"], num_classes=CFG[\"num_classes\"],\n",
        "        embed_dim=CFG[\"embed_dim\"], depth=CFG[\"depth\"], num_heads=CFG[\"num_heads\"],\n",
        "        mlp_ratio=CFG[\"mlp_ratio\"], drop_rate=CFG[\"dropout\"], drop_path=CFG[\"drop_path\"],\n",
        "    ).to(device)\n",
        "    model_eval.load_state_dict(ckpt[\"state_dict\"])\n",
        "else:\n",
        "    model_eval = None\n",
        "\n",
        "def make_test_loader():\n",
        "    _, test_bs = try_loader_oom(test_set, CFG[\"batch_size_target\"], shuffle=False)\n",
        "    return make_loader(test_set, test_bs, shuffle=False)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_acc_only(model, loader):\n",
        "    model.eval()\n",
        "    acc = MulticlassAccuracy(num_classes=CFG[\"num_classes\"]).to(device)\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
        "        logits = model(x); acc.update(logits, y)\n",
        "    return acc.compute().item()\n",
        "\n",
        "from textwrap import dedent\n",
        "\n",
        "if model_eval is not None:\n",
        "    test_loader = make_test_loader()\n",
        "    acc = test_acc_only(model_eval, test_loader)\n",
        "    test_acc_pct = round(acc*100, 2)\n",
        "    row = {\"input\": CFG[\"input_size\"], \"patch\": CFG[\"patch_size\"], \"dim\": CFG[\"embed_dim\"],\n",
        "           \"depth\": CFG[\"depth\"], \"heads\": CFG[\"num_heads\"], \"drop_path\": CFG[\"drop_path\"],\n",
        "           \"epochs\": CFG[\"epochs\"], \"test_acc%\": test_acc_pct}\n",
        "    print(\"Results row:\", row)\n",
        "\n",
        "    final_json = {\"run_id\": CFG[\"run_id\"], \"config\": CFG, \"best_val_acc\": float(ckpt.get(\"best_val_acc\", 0.0)), \"final_test_acc_pct\": float(test_acc_pct)}\n",
        "    with open(os.path.join(CFG[\"out_dir\"], \"results_final.json\"), \"w\") as f: json.dump(final_json, f, indent=2)\n",
        "\n",
        "    table = dedent(f\"\"\"\n",
        "    | Config | Input | Patch | Dim | Depth | Heads | DropPath | Epochs | Test Acc (%) |\n",
        "    |---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
        "    | {CFG['run_id']} | {CFG['input_size']}×{CFG['input_size']} | {CFG['patch_size']} | {CFG['embed_dim']} | {CFG['depth']} | {CFG['num_heads']} | {CFG['drop_path']} | {CFG['epochs']} | **{test_acc_pct}** |\n",
        "    \"\"\")\n",
        "    print(table)\n",
        "    with open(os.path.join(CFG[\"out_dir\"], \"results_table.md\"), \"w\") as f: f.write(table)\n",
        "else:\n",
        "    print(\"No best checkpoint found; run training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da61661d",
      "metadata": {
        "id": "da61661d"
      },
      "source": [
        "## (Optional) Sanity check — tokens & forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "225544ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "225544ed",
        "outputId": "222e747f-ebe6-4333-9f9b-f14872536d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens incl. CLS: 65\n",
            "Forward ok. Logits shape: torch.Size([2, 10])\n"
          ]
        }
      ],
      "source": [
        "#Sanity Check\n",
        "N = CFG[\"input_size\"] // CFG[\"patch_size\"]\n",
        "tokens = N*N + 1\n",
        "print(\"Tokens incl. CLS:\", tokens)\n",
        "x = torch.randn(2, 3, CFG[\"input_size\"], CFG[\"input_size\"]).to(device)\n",
        "m = ViT(img_size=CFG[\"input_size\"], patch_size=CFG[\"patch_size\"], num_classes=CFG[\"num_classes\"],\n",
        "        embed_dim=CFG[\"embed_dim\"], depth=CFG[\"depth\"], num_heads=CFG[\"num_heads\"],\n",
        "        mlp_ratio=CFG[\"mlp_ratio\"], drop_rate=CFG[\"dropout\"], drop_path=CFG[\"drop_path\"]).to(device)\n",
        "with torch.inference_mode(): out = m(x)\n",
        "print(\"Forward ok. Logits shape:\", out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf8c3026",
      "metadata": {
        "id": "bf8c3026"
      },
      "source": [
        "## Bonus: Short, crisp analysis (for README)\n",
        "\n",
        "- **Patch size (32×)**: `p=4` (65 tokens incl. CLS) > `p=8` (17 tokens) for CIFAR-10 detail.\n",
        "- **Depth/Width**: Small (dim=384, L=12, H=6) > Tiny (dim=192) on Colab.\n",
        "- **Regularization**: RandAug + MixUp + LS + DropPath≈0.1 generalizes well.\n",
        "- **Schedule**: AdamW + warmup→cosine; **EMA 0.9998** can add ~0.1–0.3% test.\n",
        "- **Throughput**: 224×/p=16 (197 tokens) ≈ 9× attention compute vs 32×/p=4 (65)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}